---
title: "MC-D607 Final Project HUD-API"
author: "Marco Castro"
date: "2024-11-26"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(jsonlite)
library(tibble)
library(httr)
library(httr2)
library(stringr)
library(rvest)
library(textutils)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:


```{r read_key}

# A1: declare our global variables
source("credentials.R")

# the cities we will be analyzing
#'Abilene', 'Albuquerque', 'Denver-Aurora-Lakewood', 
target_cities <- c( 'Buffalo-Cheektowaga-Niagara Falls','San Diego-Carlsbad')


```


```{r get_hud_data_with_httr2}

# A2: Custom function to call HUD FMR & IL API
# https://www.huduser.gov/portal/dataset/fmr-api.html

call_hud <- function(endpoint) {
  
  # declare constants
  domain <- "https://www.huduser.gov"
  method   <- "fmr" # alt method is il or mtspil
  path <-paste("hudapi/public/", method, "/", endpoint,sep="")
  
  # init request
  req <- request(domain) |> 
    req_headers("Accept" = "application/json") |> 
    req_auth_bearer_token(token) |>
    req_url_path(path) |>
    req_user_agent("Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/64.0.3282.140 Safari/537.36 Edge/18.17763")
  
  # test request
  # req |> req_dry_run()
  
  # call api
  resp <- req_perform(req)
  
  # parse response
  json_resp <- resp |> 
    resp_body_string() |>
    fromJSON() 
  
  # return parsed response
  return(json_resp) 
}

```

Next, we will fetch the list of Metropolitan Areas from HUD. This step will let us retrieve the `entity_id` which we will need later to retrieve the FMR for each zip code

```{r get-metro-area-ids}
  
  # B1: Fetch Metro Area Ids from API
  metros <- call_hud("listMetroAreas")

  # B2: cleanup and filter list of metro areas 
  #     for target areas
  metro_areas <- as.data.frame(metros) |>
    # split area_name col into city and type
    separate_wider_regex(
      area_name, c(cities= ".*", ",\\s", type=".*")
    ) |>
    # split type col into state and type
    mutate(
      state = substring(type,1,2),
    ) |>
    # filter by our target areas
    filter(cities %in% target_cities) |>
    select(c('cbsa_code', 'cities', 'state')) 

  
glimpse(metro_areas)  
```

Now that we a dataframe for the metropolitan areas, with our the ids we can call the `data` method of HUD's API to retrieve the FMR values for each metropolitan are

```{r get-entity-data}

# B3: Call, clean-up and merge metra area data

# Custom function to call and clean up metro area data
get_metro_data <- function(row) {
  # use "cbsa_code" col as entity_id for API call
  entity_resp <- call_hud(paste("data", row$cbsa_code, sep="/"))
  # clean up data
  df <- as.tibble(entity_resp$data$basicdata) |>
    rename_all(~tolower(str_trim(str_replace_all(., "-", "_")))) |>
    rename(studio = efficiency) |>
    mutate( 
      cbsa_code = row$cbsa_code
    ) |>
    relocate(cbsa_code, .before=zip_code) 
}

# init df with first row
metro_fmrs <- get_metro_data(metro_areas[1,])

# loop through all other metro areas
for (i in 2:nrow(metro_areas)) {
  df <- get_metro_data(metro_areas[i,])
  metro_fmrs <- rbind(metro_fmrs, df)
}

head(metro_fmrs)

zip_codes <- metro_fmrs |>
  filter(zip_code != 'MSA level') |>
  select(c("cbsa_code", "zip_code"))
```


```{r tidy-fmr-data}
# B4:  tidy data
metro_fmr_clean <- metro_fmrs |>
  pivot_longer(
    cols = studio:four_bedroom,
    names_to = c("bedrooms"),
    values_to = "fmr"
  ) |>
  mutate(
    bedrooms = case_when(
      bedrooms == 'studio' ~ as.integer(0),
      bedrooms == 'one_bedroom' ~ as.integer(1),
      bedrooms == 'two_bedroom' ~ as.integer(2),
      bedrooms == 'three_bedroom' ~ as.integer(3),
      bedrooms == 'four_bedroom' ~ as.integer(4)
    )
  ) |>
  arrange(zip_code)

head(metro_fmr_clean, n=10)

```


This script scrapes the [Trulia] ("https://www.trulia.com/").

```{r init-scraper}

# C1: Declare parser constants

# init market rate tibble
real_estate_df <- tibble(
  zip_code = character(),
  bedrooms = integer(),
  market_rate = integer()
)

# custom function to remove misc chars
cleanup_price <- function(s) {
  t <- str_replace_all(s, "([$,])", "") #remove dollar signs and commas
  x <- gsub("^([0-9]+).*", "\\1", t) #only return first group of integers
  print(x)
  return(as.integer(x))
} 

# global vars
domain <- "https://www.trulia.com"

# update user agents
user_agent <- "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/64.0.3282.140 Safari/537.36 Edge/18.17763"
set_config(add_headers(`User-Agent` = user_agent))

```

```{r scrape-trulia}

delay <- 103
# custom function for delayed scraping
throttled_GET <- slowly(
  ~read_html(.),
  rate = rate_delay(delay)
)

# C2: Scrape Real Estate Data

# can be altered for multipage scraping
beds <- 1
current_page <- 2
start <- 1
end <- nrow(zip_codes)

# loop through zip codes list
for (i in start:end) {
  # get zip code at current index
  zip <- zip_codes[i,]$zip_code
  # randomly set the delay in seconds
  delay <- 60 + round(runif(1) * 30)
  
  print(delay)
  # print current zip
  print(zip)
  
  # build our path based on the current zip, beds and page vars 
  path <- paste(domain, "/for_rent/", zip, "_zip/", beds, "_beds/", current_page, "_p/", sep="")
  
  # send path to our throttled function 
  page_reponse <- throttled_GET(path)
  
  # find price from current page html
  result_container <- page_reponse %>% 
    html_element(xpath='//ul[@data-testid="search-result-list-container"]' )
    listings <- result_container %>% 
    html_elements(xpath = '//li//div[@data-testid="property-price"]' ) %>% 
    html_text()  

  # C3: Append to parsed real estate dataframe
  # loop through all listing prices 
  # and append to market rate tibble
  for (s in listings)
    real_estate_df <- real_estate_df |>
      add_row(zip_code = zip, bedrooms = beds, market_rate = cleanup_price(s))
  
  
  write_csv(real_estate_df, "trulia_data.csv")
}


head(real_estate_df, n=10)
```

```{r dump_parsed_data }
write_csv(real_estate_df, "trulia_data.csv")
```






