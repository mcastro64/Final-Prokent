---
title: "D607 Final Project"
author: "Marco Castro"
date: "2024-11-25"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(httr)
library(stringr)
library(rvest)
library(textutils)
```

## Overview

This script scrapes the [Trulia] ("https://www.trulia.com/").


```{r clean-up-listing-price}


# init market rate tibble
real_estate_df <- tibble(
  zip_code = character(),
  bedrooms = integer(),
  market_rate = integer()
)

# custom function to remove misc chars
cleanup_price <- function(s) {
  t <- str_replace_all(s, "([$,])", "") #remove dollar signs and commas
  x <- gsub("^([0-9]+).*", "\\1", t) #only return first group of integers
  print(x)
  return(as.integer(x))
} 

# loop through all listing prices 
# and append to market rate tibble
for (s in listings)
  real_estate_df <- real_estate_df |>
    add_row(zip_code = zip, bedrooms = beds, market_rate = cleanup_price(s))

head(market_rates, n=10)
```



This section crawls through each search result page and grabs the unique job listing id. This will be used later to crawl the individual job listing page.




```{r crawl-search-result-pages}


# init the page counter
current_page <- 1

# init the page_ids data frame
page_ids <- data.frame()

# loop though all pages
while (current_page < last_page) {

    # This tells us to go to the next page
    current_page <- current_page + 1
}


```
